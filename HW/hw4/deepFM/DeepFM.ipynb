{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "\n",
    "from network import DeepFMNet\n",
    "from data_loader import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "EMBEDDING_SIZE = 5\n",
    "BATCH_SIZE = 512\n",
    "NROF_LAYERS = 3\n",
    "NROF_NEURONS = 50\n",
    "DEEP_OUTPUT_SIZE = 50\n",
    "NROF_OUT_CLASSES = 1\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_PATH = '../data/train_adult.pickle'\n",
    "VALID_PATH = '../data/valid_adult.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на датасет, может из-за него у нас появляется NaN в лоссе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_adult.pickle', 'rb') as f:\n",
    "    df, nrof_emb_categories, unique_categories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_cat</th>\n",
       "      <th>education_cat</th>\n",
       "      <th>marital-status_cat</th>\n",
       "      <th>occupation_cat</th>\n",
       "      <th>relationship_cat</th>\n",
       "      <th>race_cat</th>\n",
       "      <th>sex_cat</th>\n",
       "      <th>native-country_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16422</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>72812</td>\n",
       "      <td>10th</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16897</th>\n",
       "      <td>21</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>232719</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18910</th>\n",
       "      <td>18</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>117372</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30095</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>187098</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19533</th>\n",
       "      <td>32</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>191385</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  fnlwgt     education  education-num  \\\n",
       "16422   58        Private   72812          10th            6.0   \n",
       "16897   21    Without-pay  232719       HS-grad            9.0   \n",
       "18910   18   Self-emp-inc  117372          11th            7.0   \n",
       "30095   39        Private  187098   Prof-school           15.0   \n",
       "19533   32    Federal-gov  191385    Assoc-acdm           12.0   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "16422        Never-married     Other-service   Not-in-family   White     Male   \n",
       "16897        Never-married      Craft-repair       Own-child   Black     Male   \n",
       "18910        Never-married             Sales       Own-child   White     Male   \n",
       "30095   Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "19533             Divorced   Protective-serv   Not-in-family   White     Male   \n",
       "\n",
       "       ...  native-country  salary  workclass_cat education_cat  \\\n",
       "16422  ...   United-States    <50k              4             0   \n",
       "16897  ...   United-States    <50k              8            11   \n",
       "18910  ...   United-States    <50k              5             1   \n",
       "30095  ...   United-States   >=50k              4            14   \n",
       "19533  ...   United-States    <50k              1             7   \n",
       "\n",
       "      marital-status_cat  occupation_cat  relationship_cat  race_cat  sex_cat  \\\n",
       "16422                  4               8                 1         4        1   \n",
       "16897                  4               3                 3         2        1   \n",
       "18910                  4              12                 3         4        1   \n",
       "30095                  2               4                 5         4        0   \n",
       "19533                  0              11                 1         4        1   \n",
       "\n",
       "       native-country_cat  \n",
       "16422                  39  \n",
       "16897                  39  \n",
       "18910                  39  \n",
       "30095                  39  \n",
       "19533                  39  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workclass': 9,\n",
       " 'education': 16,\n",
       " 'marital-status': 7,\n",
       " 'occupation': 16,\n",
       " 'relationship': 6,\n",
       " 'race': 5,\n",
       " 'sex': 2,\n",
       " 'native-country': 42}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrof_emb_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workclass': array([' ?', ' Federal-gov', ' Local-gov', ' Never-worked', ' Private',\n",
       "        ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'],\n",
       "       dtype='<U17'),\n",
       " 'education': array([' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th',\n",
       "        ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate',\n",
       "        ' HS-grad', ' Masters', ' Preschool', ' Prof-school',\n",
       "        ' Some-college'], dtype='<U13'),\n",
       " 'marital-status': array([' Divorced', ' Married-AF-spouse', ' Married-civ-spouse',\n",
       "        ' Married-spouse-absent', ' Never-married', ' Separated',\n",
       "        ' Widowed'], dtype='<U22'),\n",
       " 'occupation': array([' ?', ' Adm-clerical', ' Armed-Forces', ' Craft-repair',\n",
       "        ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners',\n",
       "        ' Machine-op-inspct', ' Other-service', ' Priv-house-serv',\n",
       "        ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support',\n",
       "        ' Transport-moving', 'nan'], dtype='<U18'),\n",
       " 'relationship': array([' Husband', ' Not-in-family', ' Other-relative', ' Own-child',\n",
       "        ' Unmarried', ' Wife'], dtype='<U15'),\n",
       " 'race': array([' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other',\n",
       "        ' White'], dtype='<U19'),\n",
       " 'sex': array([' Female', ' Male'], dtype='<U7'),\n",
       " 'native-country': array([' ?', ' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba',\n",
       "        ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England',\n",
       "        ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti',\n",
       "        ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India',\n",
       "        ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos',\n",
       "        ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru',\n",
       "        ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico',\n",
       "        ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago',\n",
       "        ' United-States', ' Vietnam', ' Yugoslavia'], dtype='<U27')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                     0\n",
       "workclass               0\n",
       "fnlwgt                  0\n",
       "education               0\n",
       "education-num         392\n",
       "marital-status          0\n",
       "occupation            397\n",
       "relationship            0\n",
       "race                    0\n",
       "sex                     0\n",
       "capital-gain            0\n",
       "capital-loss            0\n",
       "hours-per-week          0\n",
       "native-country          0\n",
       "salary                  0\n",
       "workclass_cat           0\n",
       "education_cat           0\n",
       "marital-status_cat      0\n",
       "occupation_cat          0\n",
       "relationship_cat        0\n",
       "race_cat                0\n",
       "sex_cat                 0\n",
       "native-country_cat      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все понятно, скорее всего пропущенные значения и послужили некорректому расчету loss'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Exec-managerial', ' Adm-clerical', ' Other-service',\n",
       "       ' Prof-specialty', ' Sales', ' ?', ' Transport-moving',\n",
       "       ' Machine-op-inspct', ' Tech-support', ' Handlers-cleaners',\n",
       "       ' Protective-serv', ' Craft-repair', ' Farming-fishing', nan,\n",
       "       ' Priv-house-serv', ' Armed-Forces'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9., 10., 13., 12., 15.,  6.,  5., 14., nan,  4., 11.,  7.,  3.,\n",
       "       16.,  1.,  8.,  2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education-num'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таком случае заменим пропущенные значения, исходя из здравого смысла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education-num'] = df['education-num'].fillna(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['occupation'] = df['occupation'].fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сораняем наш тренироавочный датасет в pickle формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_adult.pickle', 'wb') as f:\n",
    "    pickle.dump([df, nrof_emb_categories, unique_categories], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичные манипуляции проводим с валидационным датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/valid_adult.pickle', 'rb') as f:\n",
    "    df, nrof_emb_categories, unique_categories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                     0\n",
       "workclass               0\n",
       "fnlwgt                  0\n",
       "education               0\n",
       "education-num          95\n",
       "marital-status          0\n",
       "occupation            115\n",
       "relationship            0\n",
       "race                    0\n",
       "sex                     0\n",
       "capital-gain            0\n",
       "capital-loss            0\n",
       "hours-per-week          0\n",
       "native-country          0\n",
       "salary                  0\n",
       "workclass_cat           0\n",
       "education_cat           0\n",
       "marital-status_cat      0\n",
       "occupation_cat          0\n",
       "relationship_cat        0\n",
       "race_cat                0\n",
       "sex_cat                 0\n",
       "native-country_cat      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education-num'] = df['education-num'].fillna(0.)\n",
    "df['occupation'] = df['occupation'].fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дамп в pickle\n",
    "with open('../data/valid_adult.pickle', 'wb') as f:\n",
    "    pickle.dump([df, nrof_emb_categories, unique_categories], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM:\n",
    "    def __init__(self):\n",
    "        self.train_dataset = CustomDataset(TRAIN_PATH)\n",
    "        self.train_loader = data_utils.DataLoader(dataset=self.train_dataset,\n",
    "                                                  batch_size=BATCH_SIZE, shuffle=True)\n",
    "        self.valid_dataset = CustomDataset(VALID_PATH)\n",
    "        self.valid_loader = data_utils.DataLoader(dataset=self.valid_dataset,\n",
    "                                                  batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "        self.log_params()\n",
    "\n",
    "        self.train_writer = SummaryWriter('./logs/train')\n",
    "        self.valid_writer = SummaryWriter('./logs/valid')\n",
    "\n",
    "        return\n",
    "\n",
    "    def build_model(self):\n",
    "        self.network = DeepFMNet(nrof_cat=self.train_dataset.nrof_emb_categories, emb_dim=EMBEDDING_SIZE,\n",
    "                                 emb_columns=self.train_dataset.embedding_columns,\n",
    "                                 numeric_columns=self.train_dataset.numeric_columns,\n",
    "                                 nrof_layers=NROF_LAYERS, nrof_neurons=NROF_NEURONS,\n",
    "                                 output_size=DEEP_OUTPUT_SIZE,\n",
    "                                 nrof_out_classes=NROF_OUT_CLASSES)\n",
    "\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.accuracy = Accuracy()\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        return\n",
    "\n",
    "    def log_params(self):\n",
    "        return\n",
    "\n",
    "    def load_model(self, restore_path=''):\n",
    "        if restore_path == '':\n",
    "            self.step = 0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return\n",
    "\n",
    "    def run_train(self):\n",
    "        print('Run train ...')\n",
    "\n",
    "        self.load_model()\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.network.train()\n",
    "\n",
    "            for features, label in self.train_loader:\n",
    "                # Reset gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                output = self.network(features)\n",
    "                # Calculate error and backpropagate\n",
    "                loss = self.loss(output, label)\n",
    "\n",
    "                output = torch.sigmoid(output)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                acc = self.accuracy(output, label.long()).item()\n",
    "\n",
    "                # Update weights with gradients\n",
    "                self.optimizer.step()\n",
    "\n",
    "                self.train_writer.add_scalar('CrossEntropyLoss', loss, self.step)\n",
    "                self.train_writer.add_scalar('Accuracy', acc, self.step)\n",
    "\n",
    "                self.step += 1\n",
    "\n",
    "                if self.step % 50 == 0:\n",
    "                    print('EPOCH %d STEP %d : train_loss: %f train_acc: %f' %\n",
    "                          (epoch, self.step, loss.item(), acc))\n",
    "\n",
    "#             self.train_writer.add_histogram('hidden_layer', self.network.linear1.weight.data, self.step)\n",
    "\n",
    "            # Run validation\n",
    "            running_loss = []\n",
    "            valid_scores = []\n",
    "            valid_labels = []\n",
    "            self.network.eval()\n",
    "            with torch.no_grad():\n",
    "                for features, label in self.valid_loader:\n",
    "                    output = self.network(features)\n",
    "                    # Calculate error and backpropagate\n",
    "                    loss = self.loss(output, label)\n",
    "\n",
    "                    running_loss.append(loss.item())\n",
    "\n",
    "                    valid_scores.extend((torch.sigmoid(output)>0.5).float())\n",
    "                    valid_labels.extend(label.long())\n",
    "            \n",
    "            valid_accuracy = self.accuracy(torch.tensor(valid_scores), torch.tensor(valid_labels)).item()\n",
    "\n",
    "            self.valid_writer.add_scalar('CrossEntropyLoss', np.mean(running_loss), self.step)\n",
    "            self.valid_writer.add_scalar('Accuracy', valid_accuracy, self.step)\n",
    "\n",
    "            print('EPOCH %d : valid_loss: %f valid_acc: %f' % (epoch, np.mean(running_loss), valid_accuracy))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run train ...\n",
      "EPOCH 0 STEP 50 : train_loss: 0.635479 train_acc: 0.716797\n",
      "EPOCH 0 : valid_loss: 0.571243 valid_acc: 0.737295\n",
      "EPOCH 1 STEP 100 : train_loss: 0.437494 train_acc: 0.792969\n",
      "EPOCH 1 : valid_loss: 0.378073 valid_acc: 0.833257\n",
      "EPOCH 2 STEP 150 : train_loss: 0.366967 train_acc: 0.818359\n",
      "EPOCH 2 : valid_loss: 0.344392 valid_acc: 0.845540\n",
      "EPOCH 3 STEP 200 : train_loss: 0.328503 train_acc: 0.851562\n",
      "EPOCH 3 : valid_loss: 0.329548 valid_acc: 0.851067\n",
      "EPOCH 4 STEP 250 : train_loss: 0.309694 train_acc: 0.871094\n",
      "EPOCH 4 : valid_loss: 0.324720 valid_acc: 0.851528\n",
      "EPOCH 5 STEP 300 : train_loss: 0.295606 train_acc: 0.876953\n",
      "EPOCH 5 : valid_loss: 0.322449 valid_acc: 0.853370\n",
      "EPOCH 6 STEP 350 : train_loss: 0.309161 train_acc: 0.857422\n",
      "EPOCH 6 : valid_loss: 0.321145 valid_acc: 0.852756\n",
      "EPOCH 7 STEP 400 : train_loss: 0.323807 train_acc: 0.843750\n",
      "EPOCH 7 : valid_loss: 0.318305 valid_acc: 0.853217\n",
      "EPOCH 8 STEP 450 : train_loss: 0.289859 train_acc: 0.857422\n",
      "EPOCH 8 : valid_loss: 0.319298 valid_acc: 0.853524\n",
      "EPOCH 9 STEP 500 : train_loss: 0.348130 train_acc: 0.816406\n",
      "EPOCH 9 : valid_loss: 0.317149 valid_acc: 0.854906\n",
      "EPOCH 10 STEP 550 : train_loss: 0.319901 train_acc: 0.853516\n",
      "EPOCH 10 : valid_loss: 0.317540 valid_acc: 0.852910\n",
      "EPOCH 11 STEP 600 : train_loss: 0.316070 train_acc: 0.865234\n",
      "EPOCH 11 : valid_loss: 0.315262 valid_acc: 0.854752\n",
      "EPOCH 12 STEP 650 : train_loss: 0.269863 train_acc: 0.880859\n",
      "EPOCH 12 : valid_loss: 0.315413 valid_acc: 0.854599\n",
      "EPOCH 13 STEP 700 : train_loss: 0.321295 train_acc: 0.828125\n",
      "EPOCH 13 : valid_loss: 0.314003 valid_acc: 0.854138\n",
      "EPOCH 14 STEP 750 : train_loss: 0.282354 train_acc: 0.871094\n",
      "EPOCH 14 : valid_loss: 0.315365 valid_acc: 0.853524\n",
      "EPOCH 15 STEP 800 : train_loss: 0.308100 train_acc: 0.865234\n",
      "EPOCH 15 : valid_loss: 0.314962 valid_acc: 0.854752\n",
      "EPOCH 16 STEP 850 : train_loss: 0.285653 train_acc: 0.875000\n",
      "EPOCH 16 : valid_loss: 0.315042 valid_acc: 0.855827\n",
      "EPOCH 17 STEP 900 : train_loss: 0.271512 train_acc: 0.876953\n",
      "EPOCH 17 : valid_loss: 0.315535 valid_acc: 0.854906\n",
      "EPOCH 18 STEP 950 : train_loss: 0.317714 train_acc: 0.849609\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-fab548fa696b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdeep_fm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepFM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdeep_fm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-b850e046ca34>\u001b[0m in \u001b[0;36mrun_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                 \u001b[1;31m# Reset gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\python_\\Course\\SiriusDL\\week08\\deepFM\\data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\python_\\Course\\SiriusDL\\week08\\deepFM\\data_loader.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deep_fm = DeepFM()\n",
    "deep_fm.run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
