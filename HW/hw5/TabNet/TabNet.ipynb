{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1908.07442.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/global_arch.png\" alt=\"Drawing\" width=\"600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ghost Batch Normalization (GBN):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBN позволяет нам обучать большие батчи и в то же время лучше обобщать. Суть GBN в том, что мы разделяем входной батч на суб-батчи равного размера (размером vbs - virtual batch size) и применяем к ним один и тот же слой BatchNorm. Все слои BatchNorm, используемые в модели, за исключением первого слоя BN, примененного к входным объектам, являются слоями GBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBN(nn.Module):\n",
    "    def __init__(self,inp,vbs=128,momentum=0.01):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(inp,momentum=momentum)\n",
    "        self.vbs = vbs\n",
    "    def forward(self,x):\n",
    "        chunk = torch.chunk(x,x.size(0)//self.vbs,0)\n",
    "        res = [self.bn(y) for y in chunk]\n",
    "        return torch.cat(res,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/feature_transformer.png\" alt=\"Drawing\" width=\"600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature Transformer__ - это место, где все выбранные фичи обрабатываются для генерации окончательного вывода. Каждый Feature Transformer состоит из нескольких Gated Linear Unit Blocks. GLU контролирует, какая информация должна быть разрешена для дальнейшего прохождения через сеть. Чтобы реализовать блок GLU, сначала мы __удваиваем__ размерность входных фичей в GLU, используя полносвязный слой(так как сама функция GLU делит размерность на 2). Затем мы нормализуем результирующую матрицу, используя слой GBN. Далее применяем __сигмоид ко второй половине__ полученных признаков и __умножаем результаты на первую половину поэлементно__ . Результат умножается на коэффициент масштабирования (в данном случае sqrt (0,5)) и добавляется ко входным данным следующего блока. Этот суммарный результат является вводом для следующего блока GLU в последовательности.<br><br>\n",
    "Определенное число блоков GLU используется во всех decision step'ах (Shared across decision steps), чтобы повысить производительность и эффективность модели. Первый shared блок GLU (или первый decision step dependent блок, если нет shared блоков) уникален, поскольку он уменьшает размер входных функций до размера, равного n_a + n_d. n_a - это размерность фичей, вводимых в Attentive Transformer на следующем шаге, а n_d - размерность фичей, используемых для вычисления окончательных результатов. Эти объекты обрабатываются вместе, пока не достигнут разделителя. Активация ReLU применяется к вектору размерности n_d. Выходные данные всех decision step'ов суммируются и проходят через полносвязный слой, чтобы сопоставить их с нужными нам выходными размерностями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLU Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что можно объединить слои FC, GBN и GLU в один слой, назовем его просто GLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self,inp_dim,out_dim,fc=None,vbs=128):\n",
    "        super().__init__()\n",
    "        if fc:\n",
    "            self.fc = fc\n",
    "        else:\n",
    "            self.fc = nn.Linear(inp_dim,out_dim*2)\n",
    "        self.bn = GBN(out_dim*2,vbs=vbs) \n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            # m.bias.data.fill_(0.001)\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        output = self.fc(input_data)\n",
    "        output = self.bn(output)\n",
    "        output = torch.nn.functional.glu(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/glu.png\" alt=\"Drawing\" width=\"600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем наконец сам Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransformer(nn.Module):\n",
    "    def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):\n",
    "        super().__init__()\n",
    "        first = True\n",
    "        self.shared = nn.ModuleList()\n",
    "        if shared:\n",
    "            self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))\n",
    "            first= False    \n",
    "            for fc in shared[1:]:\n",
    "                self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))\n",
    "        else:\n",
    "            self.shared = None\n",
    "        self.independ = nn.ModuleList()\n",
    "        if first:\n",
    "            self.independ.append(GLU(inp,out_dim,vbs=vbs))\n",
    "        for x in range(first, n_ind):\n",
    "            self.independ.append(GLU(out_dim,out_dim,vbs=vbs))\n",
    "        self.scale = torch.sqrt(torch.tensor([.5]))\n",
    "    def forward(self,x):\n",
    "        if self.shared:\n",
    "            x = self.shared[0](x)\n",
    "            for glu in self.shared[1:]:\n",
    "                x = torch.add(x, glu(x))\n",
    "                x = x*self.scale\n",
    "        for glu in self.independ:\n",
    "            x = torch.add(x, glu(x))\n",
    "            x = x*self.scale\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentive Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/attentive_transformer.png\" alt=\"Drawing\" width=\"300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь модель учит взаимосвязи между фичами и решает, какие фичи передать Feature Transformer на текущем decision step'е. Каждый Attentive Transformer состоит из полносвязного слоя, слоя GBN и Sparsemax. Attentive Transformer на каждом decision step'е получает входные фичи, обработанные фичи из предыдущего шага и Prior scales используемых фич. Prior scales представлена матрицей размера batch_size x input_features. Она инициализируется единицами и передается в Attentive Transformer каждого decision step'а и обновляется. Также есть параметр релаксации, который ограничивает то, сколько раз можно использовать определенную фичу в forward pass. Более высокое значение означает, что модель может повторно использовать одну и ту же фичу несколько раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTransformer(nn.Module):\n",
    "    def __init__(self,d_a,inp_dim,relax,vbs=128):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d_a,inp_dim)\n",
    "        self.bn = GBN(inp_dim,vbs=vbs)\n",
    "        self.smax = Sparsemax()\n",
    "        self.r = relax\n",
    "    #a:feature from previous decision step\n",
    "    def forward(self,a,priors): \n",
    "        a = self.bn(self.fc(a)) \n",
    "        mask = self.smax(a*priors) \n",
    "        priors =priors*(self.r-mask)  #updating the prior\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsemax https://github.com/KrisKorrel/sparsemax-pytorch/blob/master/sparsemax.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sparsemax__ - это функция активации, как и softmax, но, как следует из названия, распределение более разреженное. То есть, по сравнению с softmax, некоторые числа в распределении вероятности выхода намного ближе к 1, а другие - к 0. Это позволяет модели более эффективно выбирать релевантные фичи на каждом decision step'е. Мы будем использовать sparsemax, чтобы спроецировать маску для feature selection на каждом шаге"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы еще больше увеличить разреженность маски, можно добавить метод регуляризации разреженности, чтобы \"наказывать\" менее разреженные маски. Это может быть реализовано на каждом шаге принятия решения следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(mask*torch.log(mask+1e-10)).mean() #F(x)= -∑xlog(x+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сумма этого значения по всем шагам решения может быть добавлена к общему лоссу (после умножения на константу регуляризации λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sparsemax activation function.\n",
    "Pytorch implementation of Sparsemax function from:\n",
    "-- \"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\"\n",
    "-- André F. T. Martins, Ramón Fernandez Astudillo (http://arxiv.org/abs/1602.02068)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Sparsemax(nn.Module):\n",
    "    \"\"\"Sparsemax function.\"\"\"\n",
    "\n",
    "    def __init__(self, dim=None):\n",
    "        \"\"\"Initialize sparsemax activation\n",
    "        \n",
    "        Args:\n",
    "            dim (int, optional): The dimension over which to apply the sparsemax function.\n",
    "        \"\"\"\n",
    "        super(Sparsemax, self).__init__()\n",
    "\n",
    "        self.dim = -1 if dim is None else dim\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function.\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor. First dimension should be the batch size\n",
    "        Returns:\n",
    "            torch.Tensor: [batch_size x number_of_logits] Output tensor\n",
    "        \"\"\"\n",
    "        # Sparsemax currently only handles 2-dim tensors,\n",
    "        # so we reshape to a convenient shape and reshape back after sparsemax\n",
    "        input = input.transpose(0, self.dim)\n",
    "        original_size = input.size()\n",
    "        input = input.reshape(input.size(0), -1)\n",
    "        input = input.transpose(0, 1)\n",
    "        dim = 1\n",
    "\n",
    "        number_of_logits = input.size(dim)\n",
    "\n",
    "        # Translate input by max for numerical stability\n",
    "        input = input - torch.max(input, dim=dim, keepdim=True)[0].expand_as(input)\n",
    "\n",
    "        # Sort input in descending order.\n",
    "        # (NOTE: Can be replaced with linear time selection method described here:\n",
    "        # http://stanford.edu/~jduchi/projects/DuchiShSiCh08.html)\n",
    "        zs = torch.sort(input=input, dim=dim, descending=True)[0]\n",
    "        range = torch.arange(start=1, end=number_of_logits + 1, step=1, dtype=input.dtype).view(1, -1)\n",
    "        range = range.expand_as(zs)\n",
    "\n",
    "        # Determine sparsity of projection\n",
    "        bound = 1 + range * zs\n",
    "        cumulative_sum_zs = torch.cumsum(zs, dim)\n",
    "        is_gt = torch.gt(bound, cumulative_sum_zs).type(input.type())\n",
    "        k = torch.max(is_gt * range, dim, keepdim=True)[0]\n",
    "\n",
    "        # Compute threshold function\n",
    "        zs_sparse = is_gt * zs\n",
    "\n",
    "        # Compute taus\n",
    "        taus = (torch.sum(zs_sparse, dim, keepdim=True) - 1) / k\n",
    "        taus = taus.expand_as(input)\n",
    "\n",
    "        # Sparsemax\n",
    "        self.output = torch.max(torch.zeros_like(input), input - taus)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        output = self.output\n",
    "        output = output.transpose(0, 1)\n",
    "        output = output.reshape(original_size)\n",
    "        output = output.transpose(0, self.dim)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward function.\"\"\"\n",
    "        dim = 1\n",
    "\n",
    "        nonzeros = torch.ne(self.output, 0)\n",
    "        sum = torch.sum(grad_output * nonzeros, dim=dim) / torch.sum(nonzeros, dim=dim)\n",
    "        self.grad_input = nonzeros * (grad_output - sum.expand_as(grad_output))\n",
    "\n",
    "        return self.grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собираем все слои в одну большую сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим Attention Transformer и Feature Transformer в Decision Step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStep(nn.Module):\n",
    "    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):\n",
    "        super().__init__()\n",
    "        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)\n",
    "        self.atten_tran =  AttentionTransformer(n_a,inp_dim,relax,vbs)\n",
    "    def forward(self,x,a,priors):\n",
    "        mask = self.atten_tran(a,priors)\n",
    "        sparse_loss = ((-1)*mask*torch.log(mask+1e-10)).mean()\n",
    "        x = self.fea_tran(x*mask)\n",
    "        return x,sparse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, мы можем завершить модель, объединив несколько Decision step'ов вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNet(nn.Module):\n",
    "    def __init__(self,inp_dim,final_out_dim,n_d=64,n_a=64,\n",
    "n_shared=2,n_ind=2,n_steps=5,relax=1.2,vbs=128):\n",
    "        super().__init__()\n",
    "        if n_shared>0:\n",
    "            self.shared = nn.ModuleList()\n",
    "            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))\n",
    "            for x in range(n_shared-1):\n",
    "                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))\n",
    "        else:\n",
    "            self.shared=None\n",
    "        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) \n",
    "        self.steps = nn.ModuleList()\n",
    "        for x in range(n_steps-1):\n",
    "            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))\n",
    "        self.fc = nn.Linear(n_d,final_out_dim)\n",
    "        self.bn = nn.BatchNorm1d(inp_dim)\n",
    "        self.n_d = n_d\n",
    "    def forward(self,x):\n",
    "        x = self.bn(x)\n",
    "        x_a = self.first_step(x)[:,self.n_d:]\n",
    "        sparse_loss = torch.zeros(1)\n",
    "        out = torch.zeros(x.size(0),self.n_d)\n",
    "        priors = torch.ones(x.shape)\n",
    "        for step in self.steps:\n",
    "            x_te,l = step(x,x_a,priors)\n",
    "            out += F.relu(x_te[:,:self.n_d])\n",
    "            x_a = x_te[:,self.n_d:]\n",
    "            sparse_loss += l\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем TabNet на датасете adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "EMBEDDING_SIZE = 5\n",
    "BATCH_SIZE = 512\n",
    "INPUT_SIZE = 14\n",
    "NROF_OUT_CLASSES = 1\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_PATH = '../data/train_adult.pickle'\n",
    "VALID_PATH = '../data/valid_adult.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, train_loader, test_loader):\n",
    "    step = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "\n",
    "        for features, label in train_loader:\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(features)\n",
    "            # Calculate error and backpropagate\n",
    "            loss = criterion(output, torch.unsqueeze(label, 1))\n",
    "            loss.backward()\n",
    "            acc = accuracy(torch.sigmoid(output), torch.unsqueeze(label.long(), 1)).item()\n",
    "\n",
    "            # Update weights with gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_writer.add_scalar('CrossEntropyLoss', loss, step)\n",
    "            train_writer.add_scalar('Accuracy', acc, step)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print('EPOCH %d STEP %d : train_loss: %f train_acc: %f' %\n",
    "                      (epoch, step, loss.item(), acc))\n",
    "        \n",
    "#         train_writer.add_histogram('hidden_layer', model.linear1.weight.data, step)\n",
    "\n",
    "        \n",
    "        # Run validation\n",
    "        running_loss = []\n",
    "        valid_scores = []\n",
    "        valid_labels = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for features, label in test_loader:\n",
    "                output = model(features)\n",
    "                # Calculate error and backpropagate\n",
    "                loss = criterion(output, torch.unsqueeze(label, 1))\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "                valid_scores.extend((torch.sigmoid(output)>0.5).long())\n",
    "                valid_labels.extend(torch.unsqueeze(label, 1))\n",
    "\n",
    "        valid_accuracy = accuracy(torch.tensor(valid_scores), torch.tensor(valid_labels).long()).item()\n",
    "\n",
    "        valid_writer.add_scalar('CrossEntropyLoss', np.mean(running_loss), step)\n",
    "        valid_writer.add_scalar('Accuracy', valid_accuracy, step)\n",
    "\n",
    "        print('EPOCH %d : valid_loss: %f valid_acc: %f' % (epoch, np.mean(running_loss), valid_accuracy))\n",
    "        \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция создания train и test даталоадера\n",
    "def create_data_loader(train_dataset, train_sampler,\n",
    "                       test_dataset, test_sampler):\n",
    "    train_loader = DataLoader(dataset=train_dataset, sampler=train_sampler,\n",
    "                              batch_size=BATCH_SIZE, collate_fn=default_collate,\n",
    "                              shuffle=False)\n",
    "\n",
    "    test_loader = DataLoader(dataset=test_dataset, sampler=test_sampler,\n",
    "                             batch_size=BATCH_SIZE, collate_fn=default_collate,\n",
    "                             shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset_path):\n",
    "        super().__init__()\n",
    "        with open(dataset_path, 'rb') as f:\n",
    "            data, self.nrof_emb_categories, self.unique_categories = pickle.load(f)\n",
    "\n",
    "        self.embedding_columns = ['workclass_cat', 'education_cat', 'marital-status_cat', 'occupation_cat',\n",
    "                                  'relationship_cat', 'race_cat',\n",
    "                                  'sex_cat', 'native-country_cat']\n",
    "        self.nrof_emb_categories = {key + '_cat': val for key, val in self.nrof_emb_categories.items()}\n",
    "        self.numeric_columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "                                'hours-per-week']\n",
    "\n",
    "        self.columns = self.embedding_columns + self.numeric_columns\n",
    "\n",
    "        self.X = data[self.columns].reset_index(drop=True)\n",
    "        self.y = np.asarray([0 if el == '<50k' else 1 for el in data['salary'].values], dtype=np.int32)\n",
    "\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "#         row = self.X.take([idx], axis=0)\n",
    "\n",
    "#         row = {col: torch.tensor(row[col].values, dtype=torch.float32) for i, col in enumerate(self.columns)}\n",
    "        \n",
    "\n",
    "        return np.float32(self.X.loc[idx,:]), np.float32(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSampler(Sampler):\n",
    "\n",
    "    # Конструктор, где инициализируем индексы элементов\n",
    "    def __init__(self, data):\n",
    "        self.data_indices = np.arange(len(data))\n",
    "\n",
    "        shuffled_indices = np.random.permutation(len(self.data_indices))\n",
    "\n",
    "        self.data_indices = np.ascontiguousarray(self.data_indices)[shuffled_indices]\n",
    "\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_indices)\n",
    "\n",
    "    # Возращает итератор,\n",
    "    # который будет возвращать индексы из перемешанного датасета\n",
    "    def __iter__(self):\n",
    "        return iter(self.data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание train даталоадера и test даталоадера\n",
    "train_ds = CustomDataset(TRAIN_PATH)\n",
    "train_sampler = CustomSampler(train_ds.X)\n",
    "\n",
    "test_ds = CustomDataset(VALID_PATH)\n",
    "test_sampler = CustomSampler(test_ds.X)\n",
    "\n",
    "train_loader, test_loader = create_data_loader(train_ds, train_sampler,\n",
    "                                               test_ds, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = SummaryWriter('./logs/train')\n",
    "valid_writer = SummaryWriter('./logs/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabNet(INPUT_SIZE, NROF_OUT_CLASSES)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "accuracy = Accuracy()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 : valid_loss: 0.567650 valid_acc: 0.762629\n",
      "EPOCH 1 STEP 100 : train_loss: 0.375814 train_acc: 0.832031\n",
      "EPOCH 1 : valid_loss: 0.409507 valid_acc: 0.828036\n",
      "EPOCH 2 : valid_loss: 0.360505 valid_acc: 0.837709\n",
      "EPOCH 3 STEP 200 : train_loss: 0.343188 train_acc: 0.822266\n",
      "EPOCH 3 : valid_loss: 0.359711 valid_acc: 0.835099\n",
      "EPOCH 4 : valid_loss: 0.355420 valid_acc: 0.837402\n",
      "EPOCH 5 STEP 300 : train_loss: 0.362053 train_acc: 0.824219\n",
      "EPOCH 5 : valid_loss: 0.347919 valid_acc: 0.841241\n",
      "EPOCH 6 : valid_loss: 0.348722 valid_acc: 0.842008\n",
      "EPOCH 7 STEP 400 : train_loss: 0.345664 train_acc: 0.841797\n",
      "EPOCH 7 : valid_loss: 0.342446 valid_acc: 0.840319\n",
      "EPOCH 8 : valid_loss: 0.336144 valid_acc: 0.845386\n",
      "EPOCH 9 STEP 500 : train_loss: 0.349295 train_acc: 0.855469\n",
      "EPOCH 9 : valid_loss: 0.332235 valid_acc: 0.846307\n",
      "EPOCH 10 : valid_loss: 0.332584 valid_acc: 0.843237\n",
      "EPOCH 11 STEP 600 : train_loss: 0.356749 train_acc: 0.833984\n",
      "EPOCH 11 : valid_loss: 0.333741 valid_acc: 0.844772\n",
      "EPOCH 12 : valid_loss: 0.331786 valid_acc: 0.845233\n",
      "EPOCH 13 STEP 700 : train_loss: 0.306763 train_acc: 0.855469\n",
      "EPOCH 13 : valid_loss: 0.328899 valid_acc: 0.845079\n",
      "EPOCH 14 : valid_loss: 0.330161 valid_acc: 0.846000\n",
      "EPOCH 15 STEP 800 : train_loss: 0.308536 train_acc: 0.857422\n",
      "EPOCH 15 : valid_loss: 0.328487 valid_acc: 0.847996\n",
      "EPOCH 16 : valid_loss: 0.333653 valid_acc: 0.844158\n",
      "EPOCH 17 STEP 900 : train_loss: 0.340543 train_acc: 0.828125\n",
      "EPOCH 17 : valid_loss: 0.330977 valid_acc: 0.844772\n",
      "EPOCH 18 : valid_loss: 0.331958 valid_acc: 0.846154\n",
      "EPOCH 19 STEP 1000 : train_loss: 0.361497 train_acc: 0.826172\n",
      "EPOCH 19 : valid_loss: 0.330385 valid_acc: 0.845847\n",
      "EPOCH 20 : valid_loss: 0.331043 valid_acc: 0.845693\n",
      "EPOCH 21 STEP 1100 : train_loss: 0.347130 train_acc: 0.835938\n",
      "EPOCH 21 : valid_loss: 0.332646 valid_acc: 0.847075\n",
      "EPOCH 22 : valid_loss: 0.331068 valid_acc: 0.847996\n",
      "EPOCH 23 STEP 1200 : train_loss: 0.326199 train_acc: 0.855469\n",
      "EPOCH 23 : valid_loss: 0.331749 valid_acc: 0.847229\n",
      "EPOCH 24 : valid_loss: 0.330177 valid_acc: 0.848764\n",
      "EPOCH 25 STEP 1300 : train_loss: 0.349207 train_acc: 0.841797\n",
      "EPOCH 25 : valid_loss: 0.332068 valid_acc: 0.848918\n",
      "EPOCH 26 : valid_loss: 0.331538 valid_acc: 0.849378\n",
      "EPOCH 27 STEP 1400 : train_loss: 0.344187 train_acc: 0.863281\n",
      "EPOCH 27 : valid_loss: 0.332017 valid_acc: 0.846922\n",
      "EPOCH 28 : valid_loss: 0.330800 valid_acc: 0.845079\n",
      "EPOCH 29 STEP 1500 : train_loss: 0.268146 train_acc: 0.888672\n",
      "EPOCH 29 : valid_loss: 0.331637 valid_acc: 0.846614\n",
      "EPOCH 30 : valid_loss: 0.331367 valid_acc: 0.846000\n",
      "EPOCH 31 STEP 1600 : train_loss: 0.283396 train_acc: 0.853516\n",
      "EPOCH 31 : valid_loss: 0.330996 valid_acc: 0.846922\n",
      "EPOCH 32 : valid_loss: 0.333587 valid_acc: 0.846307\n",
      "EPOCH 33 STEP 1700 : train_loss: 0.294697 train_acc: 0.847656\n",
      "EPOCH 33 : valid_loss: 0.334744 valid_acc: 0.847536\n",
      "EPOCH 34 : valid_loss: 0.331270 valid_acc: 0.851221\n",
      "EPOCH 35 STEP 1800 : train_loss: 0.237014 train_acc: 0.892578\n",
      "EPOCH 35 : valid_loss: 0.331811 valid_acc: 0.850299\n",
      "EPOCH 36 : valid_loss: 0.333126 valid_acc: 0.846154\n",
      "EPOCH 37 STEP 1900 : train_loss: 0.319896 train_acc: 0.824219\n",
      "EPOCH 37 : valid_loss: 0.330111 valid_acc: 0.850299\n",
      "EPOCH 38 : valid_loss: 0.332911 valid_acc: 0.847075\n",
      "EPOCH 39 STEP 2000 : train_loss: 0.268422 train_acc: 0.867188\n",
      "EPOCH 39 : valid_loss: 0.330514 valid_acc: 0.847536\n",
      "EPOCH 40 : valid_loss: 0.334573 valid_acc: 0.847075\n",
      "EPOCH 41 STEP 2100 : train_loss: 0.331805 train_acc: 0.828125\n",
      "EPOCH 41 : valid_loss: 0.337900 valid_acc: 0.841855\n",
      "EPOCH 42 : valid_loss: 0.330834 valid_acc: 0.848150\n",
      "EPOCH 43 STEP 2200 : train_loss: 0.293588 train_acc: 0.857422\n",
      "EPOCH 43 : valid_loss: 0.331262 valid_acc: 0.847229\n",
      "EPOCH 44 : valid_loss: 0.331117 valid_acc: 0.845693\n",
      "EPOCH 45 STEP 2300 : train_loss: 0.311603 train_acc: 0.865234\n",
      "EPOCH 45 : valid_loss: 0.334666 valid_acc: 0.845386\n",
      "EPOCH 46 : valid_loss: 0.332350 valid_acc: 0.844926\n",
      "EPOCH 47 STEP 2400 : train_loss: 0.285804 train_acc: 0.867188\n",
      "EPOCH 47 : valid_loss: 0.333294 valid_acc: 0.845540\n",
      "EPOCH 48 : valid_loss: 0.334464 valid_acc: 0.844772\n",
      "EPOCH 49 STEP 2500 : train_loss: 0.289954 train_acc: 0.847656\n",
      "EPOCH 49 : valid_loss: 0.333065 valid_acc: 0.846768\n",
      "EPOCH 50 STEP 2600 : train_loss: 0.324280 train_acc: 0.835938\n",
      "EPOCH 50 : valid_loss: 0.334243 valid_acc: 0.844772\n",
      "EPOCH 51 : valid_loss: 0.336506 valid_acc: 0.845386\n",
      "EPOCH 52 STEP 2700 : train_loss: 0.244446 train_acc: 0.884766\n",
      "EPOCH 52 : valid_loss: 0.335648 valid_acc: 0.845693\n",
      "EPOCH 53 : valid_loss: 0.336941 valid_acc: 0.844311\n",
      "EPOCH 54 STEP 2800 : train_loss: 0.253820 train_acc: 0.898438\n",
      "EPOCH 54 : valid_loss: 0.340544 valid_acc: 0.845693\n",
      "EPOCH 55 : valid_loss: 0.339288 valid_acc: 0.845693\n",
      "EPOCH 56 STEP 2900 : train_loss: 0.300078 train_acc: 0.849609\n",
      "EPOCH 56 : valid_loss: 0.342132 valid_acc: 0.840626\n",
      "EPOCH 57 : valid_loss: 0.338957 valid_acc: 0.843544\n",
      "EPOCH 58 STEP 3000 : train_loss: 0.276368 train_acc: 0.867188\n",
      "EPOCH 58 : valid_loss: 0.342498 valid_acc: 0.843697\n",
      "EPOCH 59 : valid_loss: 0.340489 valid_acc: 0.846461\n",
      "EPOCH 60 STEP 3100 : train_loss: 0.268353 train_acc: 0.884766\n",
      "EPOCH 60 : valid_loss: 0.341403 valid_acc: 0.844158\n",
      "EPOCH 61 : valid_loss: 0.344263 valid_acc: 0.841701\n",
      "EPOCH 62 STEP 3200 : train_loss: 0.262010 train_acc: 0.878906\n",
      "EPOCH 62 : valid_loss: 0.345821 valid_acc: 0.843237\n",
      "EPOCH 63 : valid_loss: 0.344450 valid_acc: 0.842930\n",
      "EPOCH 64 STEP 3300 : train_loss: 0.219836 train_acc: 0.904297\n",
      "EPOCH 64 : valid_loss: 0.344623 valid_acc: 0.844465\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-79c8d5b6e736>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-d7bad631f2be>\u001b[0m in \u001b[0;36mrun_train\u001b[1;34m(model, train_loader, test_loader)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[1;31m# Reset gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-cebc81c4b55e>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-cebc81c4b55e>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2873\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2874\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2875\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m         \u001b[1;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   3530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3531\u001b[0m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3532\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3533\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miget\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \"\"\"\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mblknos\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\m2-user\\pycharmprojects\\python_\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = run_train(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
